{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for NLP - Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RULES:\n",
    "\n",
    "* Do not create any additional cell\n",
    "\n",
    "* Fill in the blanks\n",
    "\n",
    "* All cells should be runnable (modulo trivial compatibility bugs that we'd fix)\n",
    "\n",
    "* 4 / 20 points will be allocated to the clarity of your code\n",
    "\n",
    "* Efficient code will have a bonus\n",
    "\n",
    "DELIVERABLE:\n",
    "\n",
    "* this notebook\n",
    "* the predictions of the SST test set\n",
    "\n",
    "DO NOT INCLUDE THE DATASETS IN THE DELIVERABLE.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Monolingual (English) word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2vec():\n",
    "    def __init__(self, fname, nmax=100000):\n",
    "        self.load_wordvec(fname, nmax)\n",
    "        self.word2id = dict.fromkeys(self.word2vec.keys())\n",
    "        self.id2word = {v: k for k, v in self.word2id.items()}\n",
    "        self.embeddings = np.array(self.word2vec.values())\n",
    "    \n",
    "    def load_wordvec(self, fname, nmax):\n",
    "        self.word2vec = {}\n",
    "        with io.open(fname, encoding='utf-8') as f:\n",
    "            next(f)\n",
    "            for i, line in enumerate(f):\n",
    "                word, vec = line.split(' ', 1)\n",
    "                self.word2vec[word] = np.fromstring(vec, sep=' ')\n",
    "                if i == (nmax - 1):\n",
    "                    break\n",
    "        print('Loaded %s pretrained word vectors' % (len(self.word2vec)))\n",
    "\n",
    "    def most_similar(self, w, K=5):\n",
    "        keys_word = list(self.word2vec.keys())\n",
    "        scores_data = np.zeros(len(keys_word))\n",
    "        \n",
    "        for ind, word in enumerate(keys_word):\n",
    "            scores_data[ind] = self.score(w, word)\n",
    "            \n",
    "        inds_words = np.argsort(scores_data)[-K:]\n",
    "        words_close = np.array(keys_word)[inds_words]\n",
    "        # K most similar words: self.score  -  np.argsort \n",
    "        return(words_close)\n",
    "\n",
    "    def score(self, w1, w2):\n",
    "        vec1 = self.word2vec[w1]\n",
    "        vec2 = self.word2vec[w2]\n",
    "        \n",
    "        score_cosine = vec1.dot(vec2)/(np.linalg.norm(vec1)*np.linalg.norm(vec2))\n",
    "        # cosine similarity: np.dot  -  np.linalg.norm\n",
    "        return(score_cosine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 pretrained word vectors\n",
      "cat dog 0.671683666279249\n",
      "dog pet 0.684206402966922\n",
      "dogs cats 0.7074389328052404\n",
      "paris france 0.7775108541288563\n",
      "germany berlin 0.7420295235998394\n",
      "['feline' 'kitten' 'kitty' 'cats' 'cat']\n",
      "['doggie' 'Dog' 'puppy' 'dogs' 'dog']\n",
      "['doggies' 'Dogs' 'pooches' 'dog' 'dogs']\n",
      "['berlin' 'london' 'Paris' 'france' 'paris']\n",
      "['berlin' 'german' 'europe' 'austria' 'germany']\n"
     ]
    }
   ],
   "source": [
    "w2v = Word2vec(os.path.join(PATH_TO_DATA, 'crawl-300d-200k.vec'), nmax=100000)\n",
    "\n",
    "# You will be evaluated on the output of the following:\n",
    "for w1, w2 in zip(('cat', 'dog', 'dogs', 'paris', 'germany'), ('dog', 'pet', 'cats', 'france', 'berlin')):\n",
    "    print(w1, w2, w2v.score(w1, w2))\n",
    "for w1 in ['cat', 'dog', 'dogs', 'paris', 'germany']:\n",
    "    print(w2v.most_similar(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoV():\n",
    "    def __init__(self, w2v):\n",
    "        self.w2v = w2v\n",
    "    \n",
    "    def encode(self, sentences, idf=False):\n",
    "        # takes a list of sentences, outputs a numpy array of sentence embeddings\n",
    "        # see TP1 for help\n",
    "        sentemb = []\n",
    "        for sent in sentences:\n",
    "            if idf is False:\n",
    "                vect = []\n",
    "                for ind, w in enumerate(sent):\n",
    "                    try:\n",
    "                        vect.append(self.w2v.word2vec[w])\n",
    "                    except:\n",
    "                        #print(\"not in the dataset : \" + w)\n",
    "                        pass\n",
    "                vect = np.vstack(vect)\n",
    "                sentemb.append(np.mean(vect, axis = 0))\n",
    "                # mean of word vectors\n",
    "            else:\n",
    "                vect = []\n",
    "                for ind, w in enumerate(sent):\n",
    "                    try:\n",
    "                        vect.append(self.w2v.word2vec[w]*idf[w])\n",
    "                    except:\n",
    "                        #print(\"not in the dataset : \" + w)\n",
    "                        pass\n",
    "                vect = np.vstack(vect)\n",
    "                sentemb.append(np.mean(vect, axis = 0))\n",
    "                # idf-weighted mean of word vectors\n",
    "        return np.vstack(sentemb)\n",
    "\n",
    "    def most_similar(self, s, sentences, idf=False, K=5):\n",
    "        # get most similar sentences and **print** them\n",
    "        keys = self.encode(sentences, idf)\n",
    "        query = self.encode([s], idf)\n",
    "        \n",
    "        scores_data = np.zeros(len(keys))\n",
    "        for ind, sent in enumerate(keys):\n",
    "            scores_data[ind] = self.score(np.array(query), np.array(sent), idf)\n",
    "            \n",
    "        inds_sent = np.argsort(scores_data)[-K:]\n",
    "        sent_close = np.array(sentences)[inds_sent]\n",
    "        print('phrases proches', sent_close)\n",
    "        # K most similar words: self.score  -  np.argsort\n",
    "        return(sent_close)\n",
    "\n",
    "    def score(self, s1, s2, idf=False):\n",
    "        if type(s1) == list:\n",
    "            s1 = np.array(self.encode([s1], idf))\n",
    "            s2 = np.array(self.encode([s2], idf)).transpose()\n",
    "        score_cosine = s1.dot(s2)/(np.linalg.norm(s1)*np.linalg.norm(s2))\n",
    "        # cosine similarity: use   np.dot  and  np.linalg.norm\n",
    "        return(score_cosine)\n",
    "    \n",
    "    def build_idf(self, sentences):\n",
    "        # build the idf dictionary: associate each word to its idf value\n",
    "        idf = {}\n",
    "        for sent in sentences:\n",
    "            for w in set(sent):\n",
    "                idf[w] = idf.get(w, 0) + 1\n",
    "        \n",
    "        for word in idf.keys():\n",
    "            idf[word] = max(1, np.log10(len(sentences) / (idf[word])))\n",
    "            \n",
    "        return(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrases proches [list(['an', 'african', 'american', 'man', 'is', 'sitting', '.'])\n",
      " list(['an', 'afican', 'american', 'woman', 'standing', 'behind', 'two', 'small', 'african', 'american', 'children', '.'])\n",
      " list(['a', 'little', 'african', 'american', 'boy', 'and', 'girl', 'looking', 'up', '.'])\n",
      " list(['an', 'african', 'american', 'man', 'smiling', '.'])\n",
      " list(['1', 'smiling', 'african', 'american', 'boy', '.'])]\n",
      "[[0.57262589]]\n",
      "phrases proches [list(['an', 'afican', 'american', 'woman', 'standing', 'behind', 'two', 'small', 'african', 'american', 'children', '.'])\n",
      " list(['a', 'little', 'african', 'american', 'boy', 'and', 'girl', 'looking', 'up', '.'])\n",
      " list(['an', 'african', 'american', 'man', 'is', 'sitting', '.'])\n",
      " list(['an', 'african', 'american', 'man', 'smiling', '.'])\n",
      " list(['1', 'smiling', 'african', 'american', 'boy', '.'])]\n",
      "[[0.47514509]]\n"
     ]
    }
   ],
   "source": [
    "#w2v = Word2vec(os.path.join(PATH_TO_DATA, 'crawl-300d-200k.vec'), nmax=100000)\n",
    "s2v = BoV(w2v)\n",
    "\n",
    "# Load sentences in \"PATH_TO_DATA/sentences.txt\"\n",
    "sentences = [] #list of list of words\n",
    "with io.open(os.path.join(PATH_TO_DATA, 'sentences.txt'), encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            sentences.append(line.split())\n",
    "            \n",
    "# Build idf scores for each word\n",
    "s2v.build_idf(sentences)\n",
    "idf = {} if True else s2v.build_idf(sentences)\n",
    "\n",
    "# You will be evaluated on the output of the following:\n",
    "s2v.most_similar('' if not sentences else sentences[10], sentences)  # BoV-mean\n",
    "print(s2v.score('' if not sentences else sentences[7], '' if not sentences else sentences[13]))\n",
    "\n",
    "\n",
    "idf = s2v.build_idf(sentences)\n",
    "s2v.most_similar('' if not sentences else sentences[10], sentences, idf)  # BoV-idf\n",
    "print(s2v.score('' if not sentences else sentences[7], '' if not sentences else sentences[13], idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Multilingual (English-French) word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a bilingual dictionary of size V_a (e.g French-English).\n",
    "\n",
    "Let's define **X** and **Y** the **French** and **English** matrices.\n",
    "\n",
    "They contain the embeddings associated to the words in the bilingual dictionary.\n",
    "\n",
    "We want to find a **mapping W** that will project the source word space (e.g French) to the target word space (e.g English).\n",
    "\n",
    "Procrustes : **W\\* = argmin || W.X - Y ||  s.t  W^T.W = Id**\n",
    "has a closed form solution:\n",
    "**W = U.V^T  where  U.Sig.V^T = SVD(Y.X^T)**\n",
    "\n",
    "In what follows, you are asked to: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 pretrained word vectors\n",
      "Loaded 50000 pretrained word vectors\n"
     ]
    }
   ],
   "source": [
    "# 1 - Download and load 50k first vectors of\n",
    "#     https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.vec\n",
    "#     https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.vec\n",
    "\n",
    "# TYPE CODE HERE\n",
    "\n",
    "def load_wordvec(fname, nmax):\n",
    "        word2vec = {}\n",
    "        with io.open(fname, encoding='utf-8') as f:\n",
    "            next(f)\n",
    "            for i, line in enumerate(f):\n",
    "                word, vec = line.split(' ', 1)\n",
    "                word2vec[word] = np.fromstring(vec, sep=' ')\n",
    "                if i == (nmax - 1):\n",
    "                    break\n",
    "        print('Loaded %s pretrained word vectors' % (len(word2vec)))\n",
    "        return(word2vec)\n",
    "        \n",
    "french_vec = os.path.join(PATH_TO_DATA, 'wiki.fr.vec')\n",
    "engl_vec = os.path.join(PATH_TO_DATA, 'wiki.en.vec')\n",
    "d = 300\n",
    "nmax = 50000\n",
    "french_w2v = load_wordvec(french_vec, nmax)\n",
    "engl_w2v = load_wordvec(engl_vec, nmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Get words that appear in both vocabs (= identical character strings)\n",
    "#     Use it to create the matrix X and Y (of aligned embeddings for these words)\n",
    "\n",
    "# TYPE CODE HERE\n",
    "def intersection_linear_complex(lst1, lst2): \n",
    "    temp = set(lst2) \n",
    "    lst3 = [value for value in lst1 if value in temp] \n",
    "    return(lst3)\n",
    "\n",
    "french_words = [*french_w2v.keys()]\n",
    "english_words = [*engl_w2v.keys()]\n",
    "\n",
    "common_words = intersection_linear_complex(french_words, english_words)\n",
    "\n",
    "french_common = np.zeros((d, len(common_words)))\n",
    "english_common = np.zeros((d, len(common_words)))\n",
    "for ind, word in enumerate(common_words):\n",
    "    french_common[:,ind] = french_w2v[word]\n",
    "    english_common[:,ind] = engl_w2v[word]\n",
    "    \n",
    "french = np.zeros((d, len(french_words)))\n",
    "english = np.zeros((d, len(english_words)))\n",
    "ind_to_french = {}\n",
    "ind_to_english = {}\n",
    "for ind, word in enumerate(french_words):\n",
    "    french[:,ind] = french_w2v[word]\n",
    "    ind_to_french[ind] = word\n",
    "for ind, word in enumerate(english_words): \n",
    "    english[:,ind] = engl_w2v[word]\n",
    "    ind_to_english[ind] = word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Solve the Procrustes using the scipy package and: scipy.linalg.svd() and get the optimal W\n",
    "#     Now W*French_vector is in the same space as English_vector\n",
    "\n",
    "# TYPE CODE HERE\n",
    "import scipy.linalg\n",
    "U, s, Vh = scipy.linalg.svd(english_common.dot(french_common.transpose()), full_matrices=False)\n",
    "\n",
    "W_opt = U.dot(Vh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English to French\n",
      "doctor : docteur\n",
      "she : elle\n",
      "why : pourquoi\n",
      "london : londres\n",
      "friend : ami\n",
      "friends : amis\n",
      "\n",
      "Français à l'anglais\n",
      "ici : here\n",
      "amis : friends\n",
      "mais : but\n",
      "crayon : pencil\n",
      "aide : help\n",
      "sanctuaire : shrine\n"
     ]
    }
   ],
   "source": [
    "# 4 - After alignment with W, give examples of English nearest neighbors of some French words (and vice versa)\n",
    "#     You will be evaluated on that part and the code above\n",
    "\n",
    "# TYPE CODE HERE\n",
    "from scipy import spatial\n",
    "\n",
    "english_hat = W_opt.dot(french)\n",
    "french_hat = (W_opt.transpose()).dot(english)\n",
    "words_french = ['ici', 'amis', 'mais', 'crayon', 'aide', 'sanctuaire']\n",
    "words_english = ['doctor', 'she', 'why', 'london','friend','friends']\n",
    "\n",
    "print(\"English to French\")\n",
    "for word in words_english:\n",
    "    dist_english_hat = scipy.spatial.distance_matrix(english_hat.transpose(), engl_w2v[word].reshape((1,-1)))\n",
    "    word_closest = np.argmin(dist_english_hat)\n",
    "    print(word + \" : \" + ind_to_french[word_closest])\n",
    "\n",
    "print(\"\")\n",
    "print(\"Français à l'anglais\")\n",
    "for word in words_french:\n",
    "    dist_french_hat = scipy.spatial.distance_matrix(french_hat.transpose(), french_w2v[word].reshape((1,-1)))\n",
    "    word_closest = np.argmin(dist_french_hat)\n",
    "    print(word + \" : \" + ind_to_english[word_closest])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to dive deeper on this subject: https://github.com/facebookresearch/MUSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Sentence classification with BoV and scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded %s pretrained word vectors : 8544 = 8544\n",
      "Loaded %s pretrained word vectors : 1101 = 1101\n",
      "Loaded %s pretrained word vectors : 2210 = 1\n"
     ]
    }
   ],
   "source": [
    "# 1 - Load train/dev/test of Stanford Sentiment TreeBank (SST)\n",
    "#     (https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)\n",
    "\n",
    "def load_sentences(fname):\n",
    "        Bov_nb = []\n",
    "        Bov_sent = []\n",
    "        with io.open(fname, encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                words = line.split(' ')\n",
    "                words[-1] = words[-1].strip()\n",
    "                if words[0].isdigit():\n",
    "                    Bov_nb.append(words[0])\n",
    "                    Bov_sent.append(words[1:])\n",
    "                else:\n",
    "                    Bov_sent.append(words)\n",
    "        print('Loaded %s pretrained word vectors : ' + str(len(Bov_sent)) + \" = \" + str(len(Bov_nb)))\n",
    "        return(Bov_nb, Bov_sent)\n",
    "    \n",
    "train_BoV_file = os.path.join(PATH_TO_DATA, 'SST', 'stsa.fine.train')\n",
    "dev_BoV_file = os.path.join(PATH_TO_DATA, 'SST', 'stsa.fine.dev')\n",
    "test_BoV_file = os.path.join(PATH_TO_DATA, 'SST', 'stsa.fine.test.X')\n",
    "\n",
    "train_sentences_list = load_sentences(train_BoV_file)\n",
    "dev_sentences_list = load_sentences(dev_BoV_file)\n",
    "test_sentences_list = load_sentences(test_BoV_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape : (8544, 300) and (8544,)\n",
      "Dev shape : (1101, 300) and (1101,)\n"
     ]
    }
   ],
   "source": [
    "# 2 - Encode sentences with the BoV model above\n",
    "\n",
    "use_idf = False\n",
    "\n",
    "if use_idf:\n",
    "    idf_train = s2v.build_idf(train_sentences_list[1])\n",
    "    idf_dev = s2v.build_idf(dev_sentences_list[1])\n",
    "else:\n",
    "    idf_train = False\n",
    "    idf_dev = False\n",
    "    \n",
    "sentences_train_array = s2v.encode(train_sentences_list[1], idf_train)\n",
    "nb_train_array = np.array(train_sentences_list[0]).astype(int)\n",
    "print(\"Training shape : \" + str(sentences_train_array.shape) + \" and \" + str(nb_train_array.shape))\n",
    "\n",
    "\n",
    "sentences_dev_array = s2v.encode(dev_sentences_list[1], idf_dev)\n",
    "nb_dev_array = np.array(dev_sentences_list[0]).astype(int)\n",
    "print(\"Dev shape : \" + str(sentences_dev_array.shape) + \" and \" + str(nb_dev_array.shape))\n",
    "\n",
    "sentences_test_array = s2v.encode(test_sentences_list[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score : 0.48829588014981273\n",
      "Dev score : 0.43142597638510444\n"
     ]
    }
   ],
   "source": [
    "# 3 - Learn Logistic Regression on top of sentence embeddings using scikit-learn\n",
    "#     (consider tuning the L2 regularization on the dev set)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression().fit(sentences_train_array, nb_train_array)\n",
    "\n",
    "print(\"Train score : \" + str(clf.score(sentences_train_array, nb_train_array)))\n",
    "print(\"Dev score : \" + str(clf.score(sentences_dev_array, nb_dev_array)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 274,  631,   52,  120,   15],\n",
       "       [ 107, 1497,  144,  429,   41],\n",
       "       [  48,  677,  274,  573,   52],\n",
       "       [  18,  387,  102, 1592,  223],\n",
       "       [   8,   94,   24,  627,  535]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "sklearn.metrics.confusion_matrix(nb_train_array, clf.predict(sentences_train_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Produce 2210 predictions for the test set (in the same order). One line = one prediction (=0,1,2,3,4).\n",
    "#     Attach the output file \"logreg_bov_y_test_sst.txt\" to your deliverable.\n",
    "#     You will be evaluated on the results of the test set.\n",
    "\n",
    "with open('logreg_bov_y_test_sst.txt', 'w') as f:\n",
    "    prediction = clf.predict(sentences_test_array)\n",
    "    for item in prediction.tolist():\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS!\n",
    "# 5 - Try to improve performance with another classifier\n",
    "#     Attach the output file \"XXX_bov_y_test_sst.txt\" to your deliverable (where XXX = the name of the classifier)\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.SVC().fit(sentences_train_array, nb_train_array)\n",
    "with open('svm_bov_y_test_sst.txt', 'w') as f:\n",
    "    prediction = clf.predict(sentences_test_array)\n",
    "    for item in prediction.tolist():\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Sentence classification with LSTMs in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anatole parre\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded %s pretrained word vectors : 8544 = 8544\n",
      "Loaded %s pretrained word vectors : 1101 = 1101\n",
      "Loaded %s pretrained word vectors : 2210 = 1\n"
     ]
    }
   ],
   "source": [
    "# 1 - Load train/dev/test sets of SST\n",
    "train_BoV_file = os.path.join(PATH_TO_DATA, 'SST', 'stsa.fine.train')\n",
    "dev_BoV_file = os.path.join(PATH_TO_DATA, 'SST', 'stsa.fine.dev')\n",
    "test_BoV_file = os.path.join(PATH_TO_DATA, 'SST', 'stsa.fine.test.X')\n",
    "\n",
    "train_sentences_list = load_sentences(train_BoV_file)\n",
    "dev_sentences_list = load_sentences(dev_BoV_file)\n",
    "test_sentences_list = load_sentences(test_BoV_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different words : 15337\n",
      "Training size : 8544\n",
      "Dev size : 1101\n",
      "Test size : 2210\n"
     ]
    }
   ],
   "source": [
    "# 2 - Transform text to integers using keras.preprocessing.text.one_hot function\n",
    "#     https://keras.io/preprocessing/text/\n",
    "\n",
    "string_sentences_list = ' '.join(str(r) for v in train_sentences_list[1] for r in v)\n",
    "\n",
    "set_words = set(keras.preprocessing.text.text_to_word_sequence(string_sentences_list))\n",
    "train_size = len(set_words)\n",
    "print(\"Number of different words : \" + str(train_size))\n",
    "train_size = 8000\n",
    "\n",
    "def sentences_list_to_int_sentences_list(sentences_list, train_size):\n",
    "    int_sentences_list = []\n",
    "    for v in sentences_list[1]:\n",
    "        string_sent = ' '.join(v)\n",
    "        int_sentences_list.append(keras.preprocessing.text.one_hot(string_sent, train_size, filters=\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\", lower=True, split=\" \")) #filters=base_filter(), \n",
    "    return(int_sentences_list)\n",
    "\n",
    "int_train_sentences_list = sentences_list_to_int_sentences_list(train_sentences_list, train_size)\n",
    "int_dev_sentences_list = sentences_list_to_int_sentences_list(dev_sentences_list, train_size)\n",
    "int_test_sentences_list = sentences_list_to_int_sentences_list(test_sentences_list, train_size)\n",
    "\n",
    "print(\"Training size : \" + str(len(int_train_sentences_list)))\n",
    "print(\"Dev size : \" + str(len(int_dev_sentences_list)))\n",
    "print(\"Test size : \" + str(len(int_test_sentences_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding input data**\n",
    "\n",
    "Models in Keras (and elsewhere) take batches of sentences of the same length as input. It is because Deep Learning framework have been designed to handle well Tensors, which are particularly suited for fast computation on the GPU.\n",
    "\n",
    "Since sentences have different sizes, we \"pad\" them. That is, we add dummy \"padding\" tokens so that they all have the same length.\n",
    "\n",
    "The input to a Keras model thus has this size : (batchsize, maxseqlen) where maxseqlen is the maximum length of a sentence in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size : (8544, 20)\n",
      "Dev size : (1101, 20)\n",
      "Test size : (2210, 20)\n"
     ]
    }
   ],
   "source": [
    "# 3 - Pad your sequences using keras.preprocessing.sequence.pad_sequences\n",
    "#     https://keras.io/preprocessing/sequence/\n",
    "\n",
    "word_embedding_d = 20\n",
    "\n",
    "array_glob_sentences = keras.preprocessing.sequence.pad_sequences(int_train_sentences_list+int_dev_sentences_list+int_test_sentences_list, maxlen=word_embedding_d, dtype='int32')\n",
    "\n",
    "array_train_sentences = array_glob_sentences[:len(int_train_sentences_list)]\n",
    "array_dev_sentences = array_glob_sentences[len(int_train_sentences_list):len(int_train_sentences_list)+len(int_dev_sentences_list)]\n",
    "array_test_sentences = array_glob_sentences[len(int_train_sentences_list)+len(int_dev_sentences_list):]\n",
    "\n",
    "def compute_train_set(sentences_list):\n",
    "    array_nb = np.zeros((len(sentences_list[0]), 5))\n",
    "    for ind, classe in enumerate(sentences_list[0]):\n",
    "        array_nb[ind, int(classe)] = 1\n",
    "    return(array_nb)\n",
    "\n",
    "array_train_nb = compute_train_set(train_sentences_list)\n",
    "array_dev_nb = compute_train_set(dev_sentences_list)\n",
    "\n",
    "print(\"Training size : \" + str(array_train_sentences.shape))\n",
    "print(\"Dev size : \" + str(array_dev_sentences.shape))\n",
    "print(\"Test size : \" + str(array_test_sentences.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Design and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anatole parre\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(20, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# 4 - Design your encoder + classifier using keras.layers\n",
    "#     In Keras, Torch and other deep learning framework, we create a \"container\" which is the Sequential() module.\n",
    "#     Then we add components to this contained : the lookuptable, the LSTM, the classifier etc.\n",
    "#     All of these components are contained in the Sequential() and are trained together.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Activation\n",
    "\n",
    "embed_dim  = word_embedding_d  # word embedding dimension\n",
    "nhid       = 20  # number of hidden units in the LSTM\n",
    "vocab_size = train_size  # size of the vocabulary\n",
    "n_classes  = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embed_dim))\n",
    "model.add(LSTM(nhid, dropout_W=0.2, dropout_U=0.2))\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 20)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 105       \n",
      "=================================================================\n",
      "Total params: 163,385\n",
      "Trainable params: 163,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 5 - Define your loss/optimizer/metrics\n",
    "\n",
    "# MODIFY CODE BELOW\n",
    "\n",
    "loss_classif     =  'categorical_crossentropy' # find the right loss for multi-class classification\n",
    "optimizer        =  'adam' # find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "# Observe how easy (but blackboxed) this is in Keras\n",
    "model.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics_classif)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8544 samples, validate on 1101 samples\n",
      "Epoch 1/10\n",
      "8544/8544 [==============================] - 17s 2ms/step - loss: 1.5945 - acc: 0.2754 - val_loss: 1.5716 - val_acc: 0.2534A: 0s - loss: 1.5952 - acc: 0.27\n",
      "Epoch 2/10\n",
      "8544/8544 [==============================] - 7s 794us/step - loss: 1.5621 - acc: 0.2849 - val_loss: 1.5627 - val_acc: 0.3070\n",
      "Epoch 3/10\n",
      "8544/8544 [==============================] - 7s 867us/step - loss: 1.5237 - acc: 0.3429 - val_loss: 1.4970 - val_acc: 0.3569\n",
      "Epoch 4/10\n",
      "8544/8544 [==============================] - 8s 909us/step - loss: 1.3988 - acc: 0.3930 - val_loss: 1.4298 - val_acc: 0.3760\n",
      "Epoch 5/10\n",
      "8544/8544 [==============================] - 8s 896us/step - loss: 1.2700 - acc: 0.4441 - val_loss: 1.4450 - val_acc: 0.3706\n",
      "Epoch 6/10\n",
      "8544/8544 [==============================] - 9s 1ms/step - loss: 1.1635 - acc: 0.4829 - val_loss: 1.4629 - val_acc: 0.3706\n",
      "Epoch 7/10\n",
      "8544/8544 [==============================] - 9s 1ms/step - loss: 1.0697 - acc: 0.5310 - val_loss: 1.5401 - val_acc: 0.3787\n",
      "Epoch 8/10\n",
      "8544/8544 [==============================] - 11s 1ms/step - loss: 0.9981 - acc: 0.5849 - val_loss: 1.6087 - val_acc: 0.3551\n",
      "Epoch 9/10\n",
      "8544/8544 [==============================] - 11s 1ms/step - loss: 0.9256 - acc: 0.6159 - val_loss: 1.6995 - val_acc: 0.3533\n",
      "Epoch 10/10\n",
      "8544/8544 [==============================] - 9s 1ms/step - loss: 0.8598 - acc: 0.6351 - val_loss: 1.7367 - val_acc: 0.3442\n"
     ]
    }
   ],
   "source": [
    "# 6 - Train your model and find the best hyperparameters for your dev set\n",
    "#     you will be evaluated on the quality of your predictions on the test set\n",
    "\n",
    "# ADAPT CODE BELOW\n",
    "bs = 120\n",
    "n_epochs = 10\n",
    "\n",
    "x_train = array_train_sentences\n",
    "y_train = array_train_nb\n",
    "x_val = array_dev_sentences\n",
    "y_val = array_dev_nb\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=bs, epochs=n_epochs, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model train loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.savefig('train_results.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model dev loss')\n",
    "plt.ylabel('val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['dev'], loc='upper left')\n",
    "plt.savefig('dev_results.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 - Generate your predictions on the test set using model.predict(x_test)\n",
    "#     https://keras.io/models/model/\n",
    "#     Log your predictions in a file (one line = one integer: 0,1,2,3,4)\n",
    "#     Attach the output file \"logreg_lstm_y_test_sst.txt\" to your deliverable.\n",
    "\n",
    "# TYPE CODE HERE\n",
    "with open('logreg_lstm_y_test_sst.txt', 'w') as f:\n",
    "    prediction = model.predict(array_test_sentences)\n",
    "    for item in prediction.tolist():\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 -- innovate !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 - Open question: find a model that is better on your dev set\n",
    "#     (e.g: use a 1D ConvNet, use a better classifier, pretrain your lookup tables ..)\n",
    "#     you will get point if the results on the test set are better: be careful of not overfitting your dev set too much..\n",
    "#     Attach the output file \"XXX_XXX_y_test_sst.txt\" to your deliverable.\n",
    "\n",
    "# TYPE CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
